{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is for compatibility with Python 2. If you are using Python 3 (recommended), you may ignore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must import the TensorFlow and numpy packages to be able to use them! We use the prefix \"tf\" to avoid having to type out the full name every time we want to use a TensorFlow command. Likewise, we prefix all numpy commands with \"np\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "tf.set_random_seed(seed)  # Tell TensorFlow to use our seed\n",
    "np.random.seed(seed)  # Tell NumPy to use our seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        if sys.version[0] == '3':\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        elif sys.version[0] == '2':\n",
    "            dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function that will allow us to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = unpickle('data_batch_1')\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is stored in a dictionary (a data structure in Python). We are interested in the labels and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[b'data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10000 images in this \"batch\", and each is stored in an array of length 3072. Why is this? Hint: The images are 32x32  \n",
    "Let's plot a random image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXyIxizD0EAYKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee0acc7048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick a random number between 0 and 9999\n",
    "random = 12\n",
    "img = dataset[b'data'][random].reshape(3,32,32).transpose(1,2,0)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3, 6, 6, 2, 6, 3, 5, 4, 0, 0, 9, 1, 3, 4, 0, 3, 7, 3, 3, 5, 2, 2, 7, 1, 1, 1, 2, 2, 0, 9, 5, 7, 9, 2, 2, 5, 2, 4, 3, 1, 1, 8, 2, 1, 1, 4, 9, 7, 8, 5, 9, 6, 7, 3, 1, 9, 0, 3, 1, 3, 5, 4, 5, 7, 7, 4, 7, 9, 4, 2, 3, 8, 0, 1, 6, 1, 1, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[b'labels'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the first 100 labels - they are stored as a list of numbers between 0 and 9, where each number corresponds to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "label_names[dataset[b'labels'][random]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the selected label is a horse.\n",
    "\n",
    "We now need to break the dataset up into training and testing sets, so lets do that using the handy `train_test_split()` function from scikit-learn. First we turn the dataset into `x_data` for the actual images and `y_data` for the corresponding labels. Then we randomly split them into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape: (10000, 3072)\n",
      "y_data shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(dataset[b'data'])  # The sample images\n",
    "y_data = np.array(dataset[b'labels'])  # The labels for the samples\n",
    "print(\"x_data shape:\", x_data.shape)\n",
    "print(\"y_data shape:\", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (9000, 3072)\n",
      "x_test shape: (1000, 3072)\n",
      "\n",
      "y_train shape: (9000,)\n",
      "y_test shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print()\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we now have separate samples and labels both for training and for testing.\n",
    "\n",
    "## Making the Fully Connected Neural Network\n",
    "\n",
    "We know that the CIFAR-10 dataset is composed of 32x32 pictures that are in color (red, green, and blue color channels).  This means that images are in $\\mathbb{R}^{32*32*3} = \\mathbb{R}^{3072}$. Because there are 10 classes, the predictions are $\\hat{y} \\in \\mathbb{R}^{10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_length = 3072\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create the fully connected layers. To make this easier, we will first make a helper function to create a fully connected layer.\n",
    "\n",
    "Notice that we use `tf.variable_scope()` and `tf.get_variable()` instead of `tf.Variable()`. We use `tf.variable_scope()` to group together all the tensors and variables we define inside it. This does a couple of nice things:\n",
    "\n",
    "- Anything we define inside the variable scope will have its name prefixed with the name of the scope\n",
    "- If we try to display the graph, it will look much more organized (remember the tensorflow tutorial?)\n",
    "- We can control whether we reuse variables or not (more on that in a few sentences)\n",
    "\n",
    "Using `tf.get_variable()` will create a `tf.Variable` if the variable does not exist yet. If the variable already exists and the variable scope is in reuse mode, it will return the original variable without creating a new one. If not in reuse mode, it will throw an error, preventing us from accidentally duplicating variables\n",
    "For these reasons using `tf.variable_scope()` is a great organizational tool and helps us avoid making mistakes by preventing accidental variable duplication. If we had used `tf.Variable()`, it would ignore these duplication rules and always make a new variable, adding a suffix onto the name if it already existed.\n",
    "\n",
    "**In summary: Always keep your code organized and safe from sneaky bugs by using `tf.variable_scope()`, and always use `tf.get_variable()` instead of `tf.Variable()`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(input_tensor, output_features, name='FC', func=tf.nn.relu):\n",
    "    \"\"\"Creates a Fully Connected Layer\n",
    "\n",
    "    Args:\n",
    "        input_tensor:  Tensor of shape `[batch, features]` that this FC layer uses as its input features.\n",
    "        output_features:  The number of features that the layer will output.\n",
    "        name:  The name of the Fully Connected layer. Will use this to define the `tf.variable_scope()`.\n",
    "        func:  The activation function to use. If `None`, uses ReLU.\n",
    "    \n",
    "    Returns:\n",
    "        A Tensor representing the output feature activations. Will have shape `[None, output_features]`.\n",
    "    \"\"\"\n",
    "    input_features = int(input_tensor.shape[1])  # Get the number of features for the input tensor\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('W', initializer=tf.truncated_normal(\n",
    "            shape=[input_features, output_features],\n",
    "            stddev=0.1))\n",
    "        b = tf.get_variable('B', initializer=tf.zeros([output_features]))\n",
    "        return func(tf.matmul(input_tensor, w) + b, name='Activations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we declare all our inputs, outputs, and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()  # Clear the graph to avoid errors from reusing variables\n",
    "\n",
    "with tf.variable_scope('Inputs'):\n",
    "    x = tf.placeholder(tf.float32, [None, input_length], name='x')\n",
    "    y = tf.placeholder(tf.int64, [None,], name='y')  # Last time we one-hot encoded our labels. Now we won't.\n",
    "\n",
    "with tf.variable_scope('Hidden-Layers'):\n",
    "    hidden1 = fc(x, 512, 'FC1')\n",
    "    hidden2 = fc(hidden1, 512, 'FC2')\n",
    "    hidden3 = fc(hidden2, 512, 'FC3')\n",
    "    \n",
    "with tf.variable_scope('Softmax'):\n",
    "    w = tf.get_variable('W', initializer=tf.truncated_normal(shape=[512, num_classes], stddev=0.1))\n",
    "    b = tf.get_variable('B', initializer=tf.zeros([num_classes]))\n",
    "    scores = tf.matmul(hidden3, w) + b\n",
    "    # Predicted probability vectors for each sample in the batch, shape = `[None, 10]`\n",
    "    pred = tf.nn.softmax(scores)\n",
    "\n",
    "with tf.variable_scope('Optimization'):\n",
    "    # Last time we used the regular cross entropy function, but this time we use the \"sparse\" version. \n",
    "    # That's because this version takes care of turning the labels into one hot encodings for us!\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores))\n",
    "    correct = tf.equal(tf.argmax(pred, axis=1), y)  # boolean 1-D Tensor of if pred was correct\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))  # scalar (0-D) Tensor of the average accuracy\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)  # Op that steps loss towards minimum\n",
    "    \n",
    "init = tf.global_variables_initializer()  # Op that initializes variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network\n",
    "We already split that dataset into training and testing sets. Now we just need to feed the training set into the model and perform gradient descent. Because the training set is large (9000 images), we will feed in only a subset of the training set at a time for each batch.\n",
    "\n",
    "*Side note: When using the whole dataset in a batch, it is called \"Gradient Descent\". When using a subset of the dataset in the batch, this is called \"Mini-Batch Gradient Descent\". When the batch size is set to 1, it is called \"Stochastic Gradient Descent\". People mix up these terms, so if you hear someone saying \"use SGD\", they probably are referring to Mini-Batch Gradient Descent rather than Stochastic Gradient Descent. Even in academic papers, people confuse these!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)  # Initialize all `tf.Variable` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1, loss=2.310238, accuracy=36.38%\n",
      "epoch  10, loss=2.003286, accuracy=34.69%\n",
      "epoch  20, loss=2.179840, accuracy=29.42%\n",
      "epoch  30, loss=2.018269, accuracy=30.42%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-835d74d4e8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ryan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100  # Do 100 full passes through the dataset before we quit training\n",
    "batch_size= 256  # Feed in only 256 images in a single batch instead of all 9,000\n",
    "\n",
    "training_size = x_train.shape[0]\n",
    "\n",
    "from math import ceil\n",
    "n_batches = ceil(training_size / batch_size)\n",
    "\n",
    "for j in range(n_epochs):\n",
    "    perm = np.random.permutation(training_size)  # Every epoch, get a new set of batches\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for i in range(0, training_size, batch_size):\n",
    "        x_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        _, batch_loss, batch_accuracy = sess.run([train_step, loss, accuracy], feed_dict={x:x_batch, y:y_batch})\n",
    "        total_loss += batch_loss\n",
    "        total_accuracy += batch_accuracy\n",
    "    if j%10 == 9 or j==n_epochs-1 or j==0:\n",
    "        print(\"epoch %3d, loss=%6f, accuracy=%.2f%%\" % (j+1, total_loss/n_batches, 100*round(total_accuracy/n_batches, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fedfc4af2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random = 37\n",
    "sample = x_train[random]\n",
    "plt.imshow(sample.reshape(3,32,32).transpose(1,2,0));\n",
    "plt.title('Selected Image')\n",
    "\n",
    "print('Prediction:', label_names[sess.run(tf.argmax(pred, axis=1), feed_dict={x:[sample]})[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
