{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tensorflow Basics Tutorial\n",
    "## What is TensorFlow?\n",
    "TensorFlow is a library for mathematical computation. It has many applications, but is primarily used for neural networks. Although there are wrapper libraries for C++ and Java, we will be using the Python API because it is the most developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is a comment. Any text after the \"#\" is not run by Python and is there to describe the code.\n",
    "\n",
    "# The next few lines make sure that the code works in both Python 3 and Python 2 (feel free to ignore if you don't understand). \n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "# In order to use TensorFlow, we need to tell Python that we want to use it.\n",
    "import tensorflow as tf     # import tensorflow, any commands will be prefixed with \"tf\"\n",
    "import numpy as np          # import numpy, any commands prefixed with \"np\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensors\n",
    "A tensor is just a multidimensional array, similar to a ndarray in numpy - any value we use in tensorflow will be a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"example1:0\", shape=(2, 2), dtype=int32)\n",
      "Tensor(\"mul:0\", shape=(2, 2), dtype=int32)\n",
      "Tensor(\"add:0\", shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()  # Don't worry about what this does, we will explain later\n",
    "\n",
    "x = tf.constant([[2,4],[1,3]], name='example1')    # create a new tf.constant called \"x\". It is a 2x2 Tensor. \n",
    "print(x)\n",
    "\n",
    "x = x*5     # multiply each element of \"x\" by 5. Re-assign \"x\" to this new tensor object. \n",
    "print(x)\n",
    "\n",
    "x = x+1     # add 1 to each element of \"x2. Re-assign \"x\" to this new tensor object.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Each tensor object has a value that either we specify directly (like in the 1st example) or is the result of other operations (like the 2nd and 3rd examples). Printing a Tensor displays the following:\n",
    "- name\n",
    "- shape\n",
    "- data type  \n",
    "\n",
    "Much like Java objects or C/C++ pointers, each time we re-assign `x` to a new tensor, the original tensor still exists on the computer somewhere - we have just made `x` refer to a different tensor object (you will notice that the name changed). The original Tensors never were modified, instead each time we did an operation on the tensor it created a new Tensor.\n",
    "  \n",
    "More importantly, we cannot get the actual value using the `print()` command. This is because all we have done so far is tell TensorFlow *how* to compute x, but did not tell it to actually *do* any computations. Tensors *represent* values, rather than *being* the actual values themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sessions\n",
    "To tell TensorFlow to actually compute things, we need to create a session. A good way to think about a session is as an administrator that manages all the tensors and operations you have defined. It will compute only what needs to be computed, keep track of variables we will need later, and try to optimize the speed of the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of x in Python: Tensor(\"add:0\", shape=(2, 2), dtype=int32)\n",
      "Value of y in Python: Tensor(\"Const:0\", shape=(), dtype=int32)\n",
      "Value of z in Python: Tensor(\"truediv:0\", shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y = tf.constant(2)   # Another constant Tensor. This one is just a scalar (a single number)\n",
    "z = x/y              # Make a new tensor by dividing x (from before) by y. Assign it to z\n",
    "\n",
    "print('Value of x in Python:', x) \n",
    "print('Value of y in Python:', y) \n",
    "print('Value of z in Python:', z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession() # To actually compute things, we need to create a session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of x in TensorFlow: \n",
      " [[11 21]\n",
      " [ 6 16]] \n",
      " Data type of the result: <class 'numpy.ndarray'> \n",
      "\n",
      "Value of y in TensorFlow: \n",
      " 2 \n",
      " Data type of the result: <class 'numpy.int32'> \n",
      "\n",
      "Value of z in TensorFlow: \n",
      " [[  5.5  10.5]\n",
      " [  3.    8. ]] \n",
      " Data type of the result: <class 'numpy.ndarray'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The eval() function asks the session to compute the value of the Tensor and return the result.\n",
    "x_eval = x.eval() \n",
    "y_eval = y.eval()\n",
    "z_eval = z.eval()\n",
    "\n",
    "print('Value of x in TensorFlow: \\n', x_eval, '\\n Data type of the result:', type(x_eval), '\\n')\n",
    "print('Value of y in TensorFlow: \\n', y_eval, '\\n Data type of the result:', type(y_eval), '\\n')\n",
    "print('Value of z in TensorFlow: \\n', z_eval, '\\n Data type of the result:', type(z_eval), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Again, notice how `print(x)` can't give us the value, but `print(x.eval())` does! `x.eval()` returns a numpy ndarray because now TensorFlow needs a way to show the actual value as a multidimensional array, and numpy is the best way to do that.\n",
    "\n",
    "Although `x.eval()` is a convenient way to evaluate `x`, it is more common instead to use the `session.run()` method. `session.run()` takes a list of Tensors as its first argument, and then evaluates each and returns them. This list of Tensors is called the \"fetches\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of x in TensorFlow: \n",
      " [[11 21]\n",
      " [ 6 16]] \n",
      "\n",
      "Value of y in TensorFlow: \n",
      " 2 \n",
      "\n",
      "Value of z in TensorFlow: \n",
      " [[  5.5  10.5]\n",
      " [  3.    8. ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python, you can unpack a list like this: `a,b,c = [x1,x2,x3]`\n",
    "# Since sess.run is asked to fetch the values of 3 Tensors, it returns a list of 3 ndarrays.\n",
    "# They are then assigned to each of `x_eval`, `y_eval`, and `z_eval`\n",
    "x_eval, y_eval, z_eval = sess.run([x, y, z])\n",
    "\n",
    "print('Value of x in TensorFlow: \\n', x_eval, '\\n')\n",
    "print('Value of y in TensorFlow: \\n', y_eval, '\\n')\n",
    "print('Value of z in TensorFlow: \\n', z_eval, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Graphs\n",
    "A Tensorflow Graph is how TensorFlow internally represents and remembers all the operations and Tensors that you define. TensorFlow uses the graph to know exactly which Tensors to compute based on the fetches you provide in the `session.run()` method. TensorFlow automatically uses a default graph which is why we never had to call any functions to make one, although we can manually specify one if we want to.\n",
    "\n",
    "Below is the graph for a simple Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src ='http://ischlag.github.io/images/graph_mess.png', alt='Image from Imanol Schlag blog'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "( ͡°_ʖ ͡°) Wow thats pretty complicated actually.\n",
    "\n",
    "Luckily TensorFlow has a way for us to group our tensors and operations together using `tf.variable_scope()`. We will get into how to actually use it at another time, but here is the same graph after grouping some of these operations together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src ='http://ischlag.github.io/images/graph_example.png', alt='Image from Imanol Schlag blog'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "( ͡~ ͜ʖ ͡°) Much better.\n",
    "\n",
    "Each node in the graph takes in Tensors and outputs Tensors. The lines (directed edges) in the graph represent the flow of data through the graph, which means they also tell TensorFlow which operations depend on which. This is how TensorFlow knows that to compute the loss value, it first needs to compute the softmax function, and the matrix multiplication, etc. The graph can also be cleared at any time using `tf.reset_default_graph()`.\n",
    "\n",
    "Don't worry too much about the details of this specific graph!\n",
    "\n",
    "## TensorFlow Objects\n",
    "### Constants\n",
    "A `tf.constant` is a tensor that does not change: it remains the same throughout the duration of a Session. It can be used to store values and is hard coded into the graph. \n",
    "\n",
    "### Placeholders\n",
    "In our first example, we used a `tf.constant` as the source of the data we wished to operate on - the problem with this is that data can never change. What we really want is a way for us to be able to have some Tensor that acts as a placeholder for our data, so that we can then feed in whatever data we have (e.g. new training/test data!).\n",
    "\n",
    "This is what the `tf.placeholder` is for. A placeholder is a Tensor that can be used to feed data into, and cannot be evaluated directly until it receives data. Once we have it, we can feed values into it by using the `feed_dict` argument of the `session.run()` method. We pass a Python dict into the `feed_dict` argument, where the dict tells us which placeholders are receiving which data. If we try to evaluate a Tensor that depends on a tf.placeholder without properly feeding in data using the `feed_dict` argument, TensorFlow will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"pow:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sess.close()                 # close the old session to get rid of all the old code\n",
    "tf.reset_default_graph()     # get rid of the previous graph\n",
    "\n",
    "# shape=[None,2] means that the data can have any sized first dimension, but must have second dimension size of 2.\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2], name='x')\n",
    "print(x)\n",
    "\n",
    "x2 = x**2                    # square each element of x\n",
    "print(x2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that we had to specify a shape for `x`. This is because TensorFlow wants to know beforehand the shape of the Tensor so that it can properly define the graph. Because we set the shape as `[None, 2]`, `x` can be fed data of shape `[1,2]` or `[1337,2]`, but not `[2,3]` or `[10,4]` or `[12, 2, 2]` for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "try:\n",
    "    sess.run(x2)             # will throw an error\n",
    "    print(\"Success?\")        # we won't ever get to print this because we will get an error before we reach it\n",
    "\n",
    "except Exception as err:     # if an error occurs, the following code should execute\n",
    "    print('Error!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We got an error because when we try to evaluate `x2`, TensorFlow looks at the graph and sees that it depends on `x`. But we never fed any data into `x`!   \n",
    "Now let's do it correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      " [[  4.  16.]\n",
      " [  1.   9.]]\n",
      "\n",
      " Result 2:\n",
      " [[  25.   36.]\n",
      " [  49.   64.]\n",
      " [  81.  100.]]\n"
     ]
    }
   ],
   "source": [
    "input_1 = np.array([[2,4],\n",
    "                    [1,3]])  # 2x2 ndarray (numpy multidimensional array) as input\n",
    "\n",
    "input_2 = np.array([[5,6],\n",
    "                    [7,8],\n",
    "                    [9,10]]) # 3x2 ndarray\n",
    "\n",
    "#In python, a dict is a structure that maps keys to values, and looks like {key1: value1, key2: value2, ...}\n",
    "#`{x: input_1}` is a dict that says that the Tensor `x` will be fed the data from the ndarray `input_1`\n",
    "\n",
    "print('Result 1:\\n', sess.run(x2, feed_dict={x: input_1}))\n",
    "print('\\n Result 2:\\n', sess.run(x2, feed_dict={x: input_2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variables\n",
    "So we have `tf.constant` which always keeps the same value, and `tf.placeholder` which we can manually set the value of for each `session.run()` call. However, we have nothing that can hold a state between `session.run()` calls that can be updated and read from by TensorFlow. To fix this, we will use a `tf.Variable`. \n",
    "\n",
    "You can use a `tf.Variable` anywhere you would use a Tensor, although you can also update the `tf.Variable` using TensorFlow operations. Unlike Tensors, a `tf.Variable` exists outside the context of a single `session.run()` call.\n",
    "\n",
    "We primarily use `tf.Variable` to hold our parameters (weights, bias, etc) because TensorFlow can update them over the course of several `session.run()` calls. To create one, you must give it an \"initializer\", which can just be some other Tensor. This is what the `tf.Variable` will use as its initial value, although it can be updated later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of x: Tensor(\"X/read:0\", shape=(10, 2), dtype=float32)\n",
      "Type of x: <class 'tensorflow.python.ops.variables.Variable'>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()    # clear graph\n",
    "sess.close()                # close the previous session\n",
    "\n",
    "x = tf.Variable(tf.random_normal([10,2]), name=\"X\")  #Create the `tf.Variable from a random Tensor of shape [10,2]`\n",
    "print(\"Value of x:\", x)\n",
    "print(\"Type of x:\", type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Importantly, a `tf.Variable` has to be initialized before using it in a session. The following code will throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "try:\n",
    "    print(sess.run(x))\n",
    "    print('Success?')  # Won't ever reach this because of the error\n",
    "except Exception:\n",
    "    print('Error!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For this reason we must call `tf.global_variables_initializer()` before trying to evaluate the `tf.Variable`. This runs the operation or tensor that was specified as the initializer for the `tf.Variable`, and uses it to assign the `tf.Variable` its initial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.73532027  0.42688787]\n",
      " [-1.07123363 -0.71279907]\n",
      " [-0.53311396 -0.54464442]\n",
      " [ 2.07838821  1.40642881]\n",
      " [-0.56161886 -0.31596965]\n",
      " [-1.15365088 -0.09548074]\n",
      " [ 0.99361444 -1.09512687]\n",
      " [ 2.47602916  0.90689105]\n",
      " [ 0.54518884  0.01539329]\n",
      " [-1.09747756 -0.35992196]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()  # This is just a TensorFlow operation. Nothing is run just yet.\n",
    "\n",
    "sess.run(init)  # Now we actually run the initialization op\n",
    "\n",
    "print(sess.run(x))  # Evaluate the `tf.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might still not be clear how this is any different than what we have been doing so far, however the true power of `tf.Variable` will become evident in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Optimization\n",
    "One strength of Tensorflow is that the programmer doesn't have to know how to calculate the gradient of the function being optimized. Instead, the library comes with several optimizers commonly used in deep learning, including Gradient Descent, Momentum, and ADAM. Below we use an optimizer to minimize the function $y=x^2$ given a random initial $x$. Obviously the correct value is for $x$ to just be zero, so lets see if TensorFlow figures that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : x = 5.000 y = 25.000\n",
      "Step 5 : x = 1.638 y = 2.684\n",
      "Step 10 : x = 0.537 y = 0.288\n",
      "Step 15 : x = 0.176 y = 0.031\n",
      "Step 20 : x = 0.058 y = 0.003\n",
      "Step 25 : x = 0.019 y = 0.000\n",
      "Step 30 : x = 0.006 y = 0.000\n",
      "Step 35 : x = 0.002 y = 0.000\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()            # clear the graph\n",
    "sess.close()                        # close the previous session\n",
    "sess = tf.InteractiveSession()      # start a new one\n",
    "\n",
    "x = tf.Variable(5.0)                # let x be a variable with initial value x=5.0\n",
    "y = x**2                            # let y = x^2\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(y) # gradient descent to minimize y, with learning rate=0.1\n",
    "\n",
    "sess.run(tf.global_variables_initializer())     # initialize all variables\n",
    "\n",
    "for i in range(40):                             # run 40 training steps of gradient descent\n",
    "    x_val, y_val = sess.run([x, y])\n",
    "    if i%5 == 0:\n",
    "        print ('Step', '{:1}'.format(i), ': x =', '{0:.3f}'.format(x_val), 'y =', '{0:.3f}'.format(y_val))\n",
    "    sess.run(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that the value of the variable `x` changes with training, and converges to (nearly) the global minimum at $x=0$ as expected; it is not exact because gradient descent is an approximation.  The Session is still responsible for running the optimization operation, and a list of operations/tensors can be passed to the `session.run()` function to extract multiple values from the model. We don't need a feed_dict because there are no placeholders defined."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
